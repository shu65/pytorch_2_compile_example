{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMB9o+6UIGW6AOECfHoLMmn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shu65/pytorch_2_compile_example/blob/main/torch_2_0_compile.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozM_wjkKShH0",
        "outputId": "404481a5-7c61-4b4b-dd63-3e3c947e5171"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (2.0.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (0.15.1)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.9/dist-packages (2.0.1)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.9/dist-packages (from torch) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.9/dist-packages (from torch) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.9/dist-packages (from torch) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.9/dist-packages (from torch) (11.7.99)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.9/dist-packages (from torch) (2.14.3)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.9/dist-packages (from torch) (10.9.0.58)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.9/dist-packages (from torch) (11.7.99)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch) (3.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch) (1.7.1)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.9/dist-packages (from torch) (10.2.10.91)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.9/dist-packages (from torch) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.9/dist-packages (from torch) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.9/dist-packages (from torch) (11.7.4.91)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch) (3.9.1)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.9/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.40.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (63.4.3)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch) (15.0.7)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch) (3.22.6)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision) (8.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchvision) (2.25.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchvision) (1.22.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch) (2.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (1.26.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (4.0.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U torch torchvision torchaudio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip list | grep torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhInZ0RZSoP3",
        "outputId": "f67382f8-b98a-42ac-993a-220218c3bcab"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch                         2.0.0\n",
            "torchaudio                    2.0.1\n",
            "torchsummary                  1.5.1\n",
            "torchtext                     0.14.1\n",
            "torchvision                   0.15.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPodUM5JUb_6",
        "outputId": "f5ba7c6c-3fea-4b3f-8f84-1571da13c860"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Mar 16 22:03:27 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   61C    P0    30W /  70W |   9529MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time \n",
        "\n",
        "import torch\n",
        "import torchvision.models as models\n",
        "import torch._dynamo\n",
        "\n",
        "\n",
        "batch_size = 64\n",
        "n_warmup_iters = 10\n",
        "n_iters = 500\n",
        "\n",
        "x = torch.randn(batch_size, 3, 224, 224).cuda()\n",
        "\n",
        "def get_mode():\n",
        "    return models.resnet18()"
      ],
      "metadata": {
        "id": "fUWz2XB4Suyh"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = get_mode().cuda()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "for _ in range(n_warmup_iters):\n",
        "    optimizer.zero_grad()\n",
        "    out = model(x)\n",
        "    out.sum().backward()\n",
        "\n",
        "torch.cuda.synchronize()\n",
        "start = time.time()\n",
        "for i in range(n_iters):\n",
        "    optimizer.zero_grad()\n",
        "    out = model(x)\n",
        "    out.sum().backward()\n",
        "    optimizer.step()\n",
        "torch.cuda.synchronize()\n",
        "elapsed_time = time.time() - start\n",
        "\n",
        "print(f\"default:{elapsed_time} sec. {batch_size*n_iters/elapsed_time} imgs/sec.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wuK3l5oSzt3",
        "outputId": "e910d0e3-f1d5-4a4c-88c8-de9b1272579c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "default:78.65860414505005 sec. 406.82135600818117 imgs/sec.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch._dynamo.reset()\n",
        "\n",
        "model = get_mode().cuda()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "# compile\n",
        "compiled_model = torch.compile(model)\n",
        "for _ in range(n_warmup_iters):\n",
        "    optimizer.zero_grad()\n",
        "    out = compiled_model(x)\n",
        "    out.sum().backward()\n",
        "\n",
        "\n",
        "torch.cuda.synchronize()\n",
        "start = time.time()\n",
        "for i in range(n_iters):\n",
        "    optimizer.zero_grad()\n",
        "    out = compiled_model(x)\n",
        "    out.sum().backward()\n",
        "    optimizer.step()\n",
        "torch.cuda.synchronize()\n",
        "elapsed_time = time.time() - start\n",
        "\n",
        "print(f\"with compile:{elapsed_time} sec. {batch_size*n_iters/elapsed_time} imgs/sec.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLgaMHhrS248",
        "outputId": "ed2c0f94-3fd1-4d57-969c-86d79cbfceaf"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "with compile:74.9407467842102 sec. 427.0040181497405 imgs/sec.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch._dynamo.reset()\n",
        "\n",
        "model = get_mode().cuda()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "# compile \n",
        "compiled_model = torch.compile(model, mode=\"reduce-overhead\")\n",
        "for _ in range(n_warmup_iters):\n",
        "    optimizer.zero_grad()\n",
        "    out = compiled_model(x)\n",
        "    out.sum().backward()\n",
        "\n",
        "torch.cuda.synchronize()\n",
        "start = time.time()\n",
        "for i in range(n_iters):\n",
        "    optimizer.zero_grad()\n",
        "    out = compiled_model(x)\n",
        "    out.sum().backward()\n",
        "    optimizer.step()\n",
        "torch.cuda.synchronize()\n",
        "elapsed_time = time.time() - start\n",
        "\n",
        "print(f\"with compile reduce-overhead:{elapsed_time} sec. {batch_size*n_iters/elapsed_time} imgs/sec.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97qqRDJiS5yy",
        "outputId": "499d7852-5425-4429-e862-2fadd4ef1cad"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "with compile reduce-overhead:79.5311849117279 sec. 402.35789313986675 imgs/sec.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch._dynamo.reset()\n",
        "\n",
        "model = get_mode().cuda()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "# compile\n",
        "compiled_model = torch.compile(model, mode=\"max-autotune\")\n",
        "for _ in range(n_warmup_iters):\n",
        "    optimizer.zero_grad()\n",
        "    out = compiled_model(x)\n",
        "    out.sum().backward()\n",
        "\n",
        "torch.cuda.synchronize()\n",
        "start = time.time()\n",
        "for i in range(n_iters):\n",
        "    optimizer.zero_grad()\n",
        "    out = compiled_model(x)\n",
        "    out.sum().backward()\n",
        "    optimizer.step()\n",
        "torch.cuda.synchronize()\n",
        "elapsed_time = time.time() - start\n",
        "\n",
        "print(f\"with compile max-autotune:{elapsed_time} sec. {batch_size*n_iters/elapsed_time} imgs/sec.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umVCY1n7S8Tq",
        "outputId": "5aa5c95b-b53c-43e3-967c-2326687e5e0c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "with compile max-autotune:74.86910438537598 sec. 427.4126191664514 imgs/sec.\n"
          ]
        }
      ]
    }
  ]
}